{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code used in part 1 of How I used machine learning to classify emails and turn them into insights.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from helpers import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from query import EmailDataset\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_df = pd.read_csv('split_emails.csv')\n",
    "emails = pd.read_csv('emails.csv')\n",
    "\n",
    "# Lets create a new frame with the data we need.\n",
    "email_df = pd.DataFrame(parse_into_emails(emails.message))\n",
    "\n",
    "# Drop emails with empty body, to or from_ columns. \n",
    "email_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flag email as important if the title start with re, fw or fwd\n",
    "email_df.loc[:, 'isImportant'] = email_df.subject.str.lower().str.split(':').apply(lambda x:x[0] in ['re', 'fw', 'fwd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_df[\"folder\"] = emails.file.str.split('/').apply(lambda x: '/'.join(x[:-1]) if type(x)==list and len(x) else None)\n",
    "email_df[\"user\"] = email_df.folder.str.split('/').apply(lambda x:x[0] if type(x)==list and len(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_num = email_df.groupby('user').apply(lambda x:x.folder.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_low = email_df.loc[email_df.user.isin(folder_num.loc[folder_num<15].index)]\n",
    "email_mid = email_df.loc[email_df.user.isin(folder_num.loc[(folder_num<=50) & (folder_num>=15)].index)]\n",
    "email_high = email_df.loc[email_df.user.isin(folder_num.loc[(folder_num>50)].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eval(train, test, email, label = 'subject'):\n",
    "    stop_words = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\n",
    "    X, model, features, trans = {}, {}, {}, {}\n",
    "    for i in email.user.unique():\n",
    "        view = train.loc[train.user == i]\n",
    "        vect = TfidfVectorizer(analyzer='word', stop_words=stop_words, max_df=0.3, min_df=2)\n",
    "        X[i] = vect.fit_transform(view.loc[:, label])\n",
    "        features[i] = vect.get_feature_names()\n",
    "        trans[i] = vect\n",
    "        lsvc = LinearSVC(multi_class='ovr', C = 1.0)\n",
    "        lsvc.fit(X[i], view.folder)\n",
    "        model[i] = lsvc\n",
    "\n",
    "    count = 0\n",
    "    for i in range(test.shape[0]):\n",
    "#         clear_output(wait=True)\n",
    "        tmp = model[test.iloc[i].user].predict(trans[test.iloc[i].user].transform([test.iloc[i].loc[label]]))\n",
    "        if (test.iloc[i].folder == tmp[0]):\n",
    "            count += 1\n",
    "#         print(\"Finished {:.2f}%\".format(i/test.shape[0]*100))\n",
    "\n",
    "    print(\"Accuracy {:2f}%\".format(count/test.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eval(train, test, email):\n",
    "    stop_words = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\n",
    "    X, model, features, trans = {}, {}, {}, {}\n",
    "    for i in email.user.unique():\n",
    "        view = train.loc[train.user == i]\n",
    "        vect = TfidfVectorizer(analyzer='word', stop_words=stop_words, max_df=0.3, min_df=2)\n",
    "        X[i] = vect.fit_transform(view.subject)\n",
    "        features[i] = vect.get_feature_names()\n",
    "        trans[i] = vect\n",
    "        lsvc = LinearSVC(multi_class='ovr', C = 1.0)\n",
    "        lsvc.fit(X[i], view.folder)\n",
    "        model[i] = lsvc\n",
    "\n",
    "    count = 0\n",
    "    for i in range(test.shape[0]):\n",
    "#         clear_output(wait=True)\n",
    "        tmp = model[test.iloc[i].user].predict(trans[test.iloc[i].user].transform([test.iloc[i].subject]))\n",
    "        if (test.iloc[i].folder == tmp[0]):\n",
    "            count += 1\n",
    "#         print(\"Finished {:.2f}%\".format(i/test.shape[0]*100))\n",
    "\n",
    "    print(\"Accuracy {:2f}%\".format(count/test.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 64.952991%\n",
      "Accuracy 23.797183%\n",
      "Accuracy 28.013724%\n",
      "Accuracy 40.767618%\n",
      "Accuracy 19.343368%\n",
      "Accuracy 21.146953%\n",
      "Accuracy 33.486811%\n",
      "Accuracy 14.753670%\n",
      "Accuracy 22.204330%\n"
     ]
    }
   ],
   "source": [
    "for email in [email_low, email_mid, email_high]:\n",
    "    # sparsity  score\n",
    "    sparsity = email.groupby(['user', 'folder']).subject.count().groupby(['user']).apply(lambda x:1/(x**2).sum()*x.sum()**2)\n",
    "\n",
    "    names = sparsity.loc[sparsity<sparsity.quantile(1/3)].index\n",
    "    email_dense = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[sparsity>sparsity.quantile(2/3)].index\n",
    "    email_sparse = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[(sparsity>=sparsity.quantile(1/3)) & (sparsity<=sparsity.quantile(2/3))].index\n",
    "    email_normal = email.loc[email.user.isin(names)]\n",
    "    for e in [email_dense, email_sparse, email_normal]:\n",
    "        check = e.copy()\n",
    "        reorder = np.arange(check.shape[0])\n",
    "        check.index = reorder\n",
    "        np.random.shuffle(reorder)\n",
    "        check = check.iloc[reorder, :]\n",
    "        check = check.dropna()\n",
    "        train, test = check.iloc[:int(e.shape[0]/5*4)], check.iloc[int(e.shape[0]/5*4):]\n",
    "        model_eval(train, test, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 63.952791%\n",
      "Accuracy 25.160563%\n",
      "Accuracy 20.678900%\n",
      "Accuracy 39.638768%\n",
      "Accuracy 19.722650%\n",
      "Accuracy 14.008363%\n",
      "Accuracy 21.577962%\n",
      "Accuracy 12.058728%\n",
      "Accuracy 17.838612%\n"
     ]
    }
   ],
   "source": [
    "for email in [email_low, email_mid, email_high]:\n",
    "    # sparsity  score\n",
    "    sparsity = email.groupby(['user', 'folder']).subject.count().groupby(['user']).apply(lambda x:1/(x**2).sum()*x.sum()**2)\n",
    "\n",
    "    names = sparsity.loc[sparsity<sparsity.quantile(1/3)].index\n",
    "    email_dense = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[sparsity>sparsity.quantile(2/3)].index\n",
    "    email_sparse = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[(sparsity>=sparsity.quantile(1/3)) & (sparsity<=sparsity.quantile(2/3))].index\n",
    "    email_normal = email.loc[email.user.isin(names)]\n",
    "    for e in [email_dense, email_sparse, email_normal]:\n",
    "        check = e.copy()\n",
    "        reorder = np.arange(check.shape[0])\n",
    "        check.index = reorder\n",
    "        np.random.shuffle(reorder)\n",
    "        check = check.iloc[reorder, :]\n",
    "        check = check.dropna()\n",
    "        train, test = check.iloc[:int(e.shape[0]/5*4)], check.iloc[int(e.shape[0]/5*4):]\n",
    "        model_eval(train, test, e, 'body')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
