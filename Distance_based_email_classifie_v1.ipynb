{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code used in part 1 of How I used machine learning to classify emails and turn them into insights.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD \n",
    "from sklearn.preprocessing import normalize \n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from query import EmailDataset\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from helpers import * \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# email_df = pd.read_csv('split_emails.csv')\n",
    "emails = pd.read_csv('emails.csv')\n",
    "\n",
    "# Lets create a new frame with the data we need.\n",
    "email_df = pd.DataFrame(parse_into_emails(emails.message))\n",
    "\n",
    "# Drop emails with empty body, to or from_ columns. \n",
    "email_df.drop(email_df.query(\"body == '' | to == '' | from_ == ''\").index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flag email as important if the title start with re, fw or fwd\n",
    "email_df.loc[:, 'isImportant'] = email_df.subject.str.lower().str.split(':').apply(lambda x:x[0] in ['re', 'fw', 'fwd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_df[\"folder\"] = emails.file.str.split('/').apply(lambda x: '/'.join(x[:-1]) if type(x)==list and len(x) else None)\n",
    "email_df[\"user\"] = email_df.folder.str.split('/').apply(lambda x:x[0] if type(x)==list and len(x) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_num = email_df.groupby('user').apply(lambda x:x.folder.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "email_low = email_df.loc[email_df.user.isin(folder_num.loc[folder_num<15].index)]\n",
    "email_mid = email_df.loc[email_df.user.isin(folder_num.loc[(folder_num<=50) & (folder_num>=15)].index)]\n",
    "email_high = email_df.loc[email_df.user.isin(folder_num.loc[(folder_num>50)].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eval(train, test, email):\n",
    "    stop_words = ENGLISH_STOP_WORDS.union(['ect', 'hou', 'com', 'recipient'])\n",
    "    X, model, features, trans = {}, {}, {}, {}\n",
    "    for i in email.user.unique():\n",
    "        view = train.loc[train.user == i]\n",
    "        vect = TfidfVectorizer(analyzer='word', stop_words=stop_words, max_df=0.3, min_df=2)\n",
    "        X[i] = vect.fit_transform(view.subject)\n",
    "        features[i] = vect.get_feature_names()\n",
    "        trans[i] = vect\n",
    "\n",
    "    count = 0\n",
    "    for i in range(test.shape[0]):\n",
    "#         clear_output(wait=True)\n",
    "        view = test.iloc[i]\n",
    "#         print(view.subject)\n",
    "        distance =  linear_kernel(trans[view.user].transform([view.subject]), X[view.user]).flatten()\n",
    "        tmp = train.loc[train.user == view.user, ['folder']]\n",
    "        tmp.loc[:, 'distance'] = distance\n",
    "        distance = tmp.groupby('folder').max()\n",
    "#         print(distance)\n",
    "        order = distance.rank(ascending=False)\n",
    "        \n",
    "#         print(test.iloc[i].folder, order.distance.argmin())\n",
    "        if (test.iloc[i].folder == order.distance.argmin()):\n",
    "            count += 1\n",
    "#             print(i)\n",
    "            \n",
    "#         print(\"Finished {:.2f}%\".format(i/test.shape[0]*100))\n",
    "\n",
    "    print(\"Accuracy {:2f}%\".format(count/test.shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for email in [email_low, email_mid, email_high]:\n",
    "    # sparsity  score\n",
    "    sparsity = email.groupby(['user', 'folder']).subject.count().groupby(['user']).apply(lambda x:1/(x**2).sum()*x.sum()**2)\n",
    "\n",
    "    names = sparsity.loc[sparsity<sparsity.quantile(1/3)].index\n",
    "    email_dense = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[sparsity>sparsity.quantile(2/3)].index\n",
    "    email_sparse = email.loc[email.user.isin(names)]\n",
    "\n",
    "    names = sparsity.loc[(sparsity>=sparsity.quantile(1/3)) & (sparsity<=sparsity.quantile(2/3))].index\n",
    "    email_normal = email.loc[email.user.isin(names)]\n",
    "    for e in [email_dense, email_sparse, email_normal]:\n",
    "        check = e.copy()\n",
    "        reorder = np.arange(check.shape[0])\n",
    "        check.index = reorder\n",
    "        np.random.shuffle(reorder)\n",
    "        check = check.iloc[reorder, :]\n",
    "        check = check.dropna()\n",
    "        train, test = check.iloc[:int(e.shape[0]/5*4)], check.iloc[int(e.shape[0]/5*4):]\n",
    "        model_eval(train, test, e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
